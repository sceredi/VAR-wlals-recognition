{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Estrazione feature hand-crafted\n",
    "Dopo aver analizzato e pre-processato i dati ([1_data_preprocessing.ipynb](./1_data_preprocessing.ipynb)) è stata effettuata l'estrazione delle feature.\n",
    "\n",
    "Le feature hand-crafted rappresentano un insieme di caratteristiche estratte manualmente dai frame appartenenti ai video, mirando a catturare aspetti specifici e distintivi che possono facilitare la successiva fase di classificazione.\n",
    "Tra le principali feature estratte vi sono quelle legate alla:\n",
    "- forma,\n",
    "- tessitura,\n",
    "- colore,\n",
    "- movimento.\n",
    "\n",
    "Sebbene ogni categoria possa offrire un contributo variabile in termini di efficacia, la loro combinazione consente di migliorare significativamente le prestazioni dei sistemi di riconoscimento."
   ],
   "id": "e590db3344b1e9c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import delle librerie",
   "id": "419cab8b5775a42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from handcrafted.app.features.plotter.frames_plotter import (\n",
    "    plot_frames,\n",
    "    plot_edge_frames,\n",
    "    plot_hog_frames,\n",
    "    plot_haar_frames,\n",
    "    plot_skin_frames,\n",
    "    plot_flow_frames,\n",
    "    plot_lbp_frames,\n",
    "    plot_color_hist,\n",
    ")\n",
    "from handcrafted.app.dataset.dataset import Dataset"
   ],
   "id": "eb544324f8cae4f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Caricamento del dataset\n",
    "Di seguito si mostra il caricamento del dataset, e l'estrazione dei frame appartenenti a due diversi video, che verranno utilizzati per mostrare l'estrazione delle features."
   ],
   "id": "69f751a6cbf572ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = Dataset(\"data/WLASL_v0.3.json\")\n",
    "\n",
    "frames_0 = dataset.videos[0].get_frames()\n",
    "frames_1 = dataset.videos[1].get_frames()\n",
    "\n",
    "frames = frames_0[10:12] + frames_1[10:12]"
   ],
   "id": "ed5e297d44b7a8bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vengono quindi plottati i frame dei due video.",
   "id": "1e5f9e7313257595"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_frames(frames)",
   "id": "9c2bf178b1c3e799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature di forma\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c221c00547d62fb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Edge extraction\n",
    "Tramite la classe [EdgeExtractor](./handcrafted/app/features/extractor/edge_extractor.py) vengono applicate una serie di trasformazioni:\n",
    "1. Conversione dell'immagine in scala di grigi;\n",
    "2. Applicazione di un filtro di sfocatura gaussiana;\n",
    "3. Applicazione di un equalizzatore di istogrammi;\n",
    "4. Utilizzo dell'operatore morfologico Sobel;\n",
    "5. Binarizzazione dell'immagine;\n",
    "6. Operatore di chiusura morfologica.\n",
    "\n",
    "Di seguito la stampa dei risultati."
   ],
   "id": "fe4e1100e5e1442c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_edge_frames(frames)",
   "id": "f86407fb8aa3c096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hog detector\n",
    "\n",
    "La classe [HogExtractor](./handcrafted/app/features/extractor/hog_extractor.py) sfrutta la libreria `skimage` per estrarre le feature in questione.\n",
    "Oltre all'immagine in scala di grigi, i parametri utilizzati per l'estrazione sono i seguenti:\n",
    "- `orientations: 9`: il numero di bin dell'istogramma di orientamento;\n",
    "- `pixels_per_cell: (8,8)`: la dimensione della cella in pixel su cui viene calcolato ogni istogramma gradiente;\n",
    "- `cells_per_block: (2,2)`: l'area locale su cui verrà normalizzato il conteggio dell'istogramma in una determinata cella;\n",
    "- `block_norm: \"L2-Hys\"`: il tipo di normalizzazione da applicare ai blocchi;\n",
    "- `visualize: True`: oltre alle feature hog, ritorna anche l'immagine dell'istogramma di orientazione risultante (mostrato sotto);\n",
    "- `transform_sqrt: True`: applica una normalizzazione per ridurre l'effetto delle ombre e migliorare la robustezza rispetto a variazioni di luminosità."
   ],
   "id": "f3f3c39f09af3a1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_hog_frames(frames)",
   "id": "2a3397552cd70ece",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature di texture",
   "id": "8c624f6fd0b3a0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Haar-like features\n",
    "\n",
    "La classe [HaarDetector](./handcrafted/app/features/extractor/haar/haar_detector.py) utilizza il classificatore pre-addestrato `CascadeClassifier` di `opencv` per localizzare i volti dei soggetti.\n",
    "Esso è basato sul metodo haar e l'algoritmo di Viola-Jones.\n",
    "Basandosi sull'immagine in scala di grigi viene equalizzato l'istogramma del frame, per migliorare il contrasto dell'immagine.\n",
    "Si utilizza quindi il classificatore per estrarre le posizioni degli oggetti rilevati.\n",
    "Siccome `CascadeClassifier` può restituire più posizioni, è stato necessario andare a selezionare quella ritenuta migliore.\n",
    "Dall'analisi del dataset si è osservato come il volto tende a non cambiare posizione durante il video.\n",
    "La posizione migliore viene quindi scelta sulla base delle posizioni precedentemente identificate, sfruttando la distanza euclidea.\n",
    "Le prime posizioni potrebbero però risultare errate sfruttando questa tecnica, in quanto il primo oggetto che viene scelto dipende dalla confidenza che il classificatore assegna alla posizione.\n",
    "Nei primi dieci frame le posizioni vengono quindi ricalcolate utilizzando la posizione media aggiornata."
   ],
   "id": "4851a577b15941cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_ = plot_haar_frames(frames)",
   "id": "3287e5bf6e064958",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "La pelle dei soggetti è stata estratta utilizzando il classificatore haar in combinazione con l'elaborazione del colore ([SkinExtractor](./handcrafted/app/features/extractor/skin.py)), i passi effettuati sono:\n",
    "1. trasformazione dello spazio colore in `HSV`;\n",
    "2. si calcolano i valori medi dei 3 canali;\n",
    "3. si utilizza un'intorno dei 3 valori medi per estrarre le porzioni dell'immagine nelle quali è presente la pelle del soggetto;\n",
    "4. viene effettuata infine una operazione di chiusura morfologica.\n",
    "\n",
    "Di seguito sono mostrati i risultati ottenuti."
   ],
   "id": "2145b6ac596f7c27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_skin_frames(frames_0[10:12])\n",
    "plot_skin_frames(frames_1[10:12])"
   ],
   "id": "b322e291a6826f70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Local Binary Patterns\n",
    "\n",
    "La classe [LBPExtractor](./handcrafted/app/features/extractor/lbp_extractor.py) sfrutta `skimage` di `opencv` per andare ad estrarre le feature LBP.\n",
    "I parametri utilizzati per l'estrazione sono i seguenti:\n",
    "- i frames in scala di grigi;\n",
    "- `radius: 3`: raggio della circonferenza su cui si trovano i pixel vicini;\n",
    "- `n_points: 8 * radius`: il numero di vicini considerati;\n",
    "- `method: uniform`: permette una maggiore robustezza al rumore e riduce la complessità dell'istogramma.\n",
    "\n",
    "In questo modo viene estratta una matrice in cui ogni valore di pixel rappresenta un valore lbp.\n",
    "Dalla matrice le feature vengono estratte andando a realizzare un istogramma, come mostrato sotto.\n",
    "L'istogramma viene inoltre normalizzato garantendo maggiore robustezza rispetto cambiamenti di scala, di illuminazione e traslazione dell'immagine."
   ],
   "id": "b29a2fe06caaf9c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_lbp_frames(frames_0[10:12])\n",
    "plot_lbp_frames(frames_1[10:12])"
   ],
   "id": "1bf5787b22bbd0a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature colore",
   "id": "36d127a0891ca689"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Color histograms\n",
    "\n",
    "La classe [ColorHistogram](./handcrafted/app/features/extractor/color_histogram_extractor.py) permette di estrarre l'istogramma colore dai frame di un video.\n",
    "Per fare questo è stata sfruttata la funzione `calcHist` di `opencv` che permette di estrarre o un istogramma per ogni canale dello spazio colore, oppure realizzarne uno multidimensionale che comprende l'intero lo spazio colore.\n",
    "È possibile andare a normalizzare gli istogrammi, la normalizzazione permette di ottene risultati più robusti rispetto a cambiamenti di scala e traslazioni."
   ],
   "id": "4f975fde1e6b6c94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_color_hist(frames_0[10:12], normalize=True)\n",
    "plot_color_hist(frames_1[10:12], normalize=True)"
   ],
   "id": "c0d2d7e6a32624de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature di movimento",
   "id": "1e44ba8ca26a3883"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optical flow\n",
    "\n",
    "La classe [FlowCalculator](./handcrafted/app/features/extractor/flow_calculator.py) sfrutta la libreria `opencv` per calcolare l'optical flow utilizzando il metodo di Gunnar Farnebäck.\n",
    "I parametri utilizzati per il calcolo sono i seguenti:\n",
    "- `pyr_scale: 0.3`: indica quanto ridurre l'immagine a ogni livello della piramide;\n",
    "- `levels: 5`: numero di livelli della piramide;\n",
    "- `winsize: 10`: dimensione della finestra per le medie ponderate;\n",
    "- `iterations: 6`: numero di iterazioni per ogni livello della piramide;\n",
    "- `poly_n: 5`: dimensione della finestra per il filtro polinomiale;\n",
    "- `poly_sigma: 1.5`: sigma per il filtro polinomiale Gaussiano.\n",
    "\n",
    "Per disegnare i risultati ottenuti si calcolano la magnitudo e l'angolo dell'optical flow:\n",
    "- l'angolo, codificato dal colore, indica la direzione del movimento;\n",
    "- la magnitudo indica l'intensità del movimento e viene rappresentata tramite la luminosità del colore.\n"
   ],
   "id": "19d933211088cffa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_flow_frames(frames_0[10:16])\n",
    "plot_flow_frames(frames_1[10:16])"
   ],
   "id": "e87680f8b1ac9206",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
