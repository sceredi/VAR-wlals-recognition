{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T10:37:51.870613Z",
     "start_time": "2025-04-01T10:37:49.285915Z"
    }
   },
   "source": [
    "import itertools\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from handcrafted.app.dataset.dataset_loader import DatasetLoader\n",
    "from handcrafted.app.dataset.utils.dataset_creator import DatasetCreator\n",
    "from handcrafted.app.dataset.utils.frames_splitter import FramesSplitter\n",
    "from handcrafted.app.model.model_statistics import ModelStatistics"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 12:37:50.107610: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 12:37:50.109597: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-01 12:37:50.131535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-01 12:37:50.131593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-01 12:37:50.132416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 12:37:50.136887: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-01 12:37:50.137607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 12:37:50.817142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1f091fd4fd7fd7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.454520Z",
     "start_time": "2025-04-01T10:37:51.875562Z"
    }
   },
   "source": [
    "loader = DatasetLoader(directory=\"./data/frames_no_bg/\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12023it [00:12, 956.16it/s] \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "67198a3f4fbcc8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.550755Z",
     "start_time": "2025-04-01T10:38:04.548527Z"
    }
   },
   "source": [
    "num_signers = 8\n",
    "if num_signers == -1:\n",
    "    signers = loader.signers\n",
    "    num_signers = loader.num_signers\n",
    "else:\n",
    "    signers = dict(itertools.islice(loader.signers.items(), num_signers))\n",
    "splitter = FramesSplitter(signers, val_split=0.3, test_split=0.3, frames_to_extract=1000, seed=42)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.595878Z",
     "start_time": "2025-04-01T10:38:04.592876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for signer in signers.values():\n",
    "    signer_frames = []\n",
    "    for video in signer.videos:\n",
    "        signer_frames.extend(video.frames)\n",
    "    print(f\"Signer {signer.id} has {len(signer_frames)} frames\")"
   ],
   "id": "17a437d4d7310b0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signer 117 has 2329 frames\n",
      "Signer 26 has 9778 frames\n",
      "Signer 63 has 3888 frames\n",
      "Signer 35 has 5184 frames\n",
      "Signer 42 has 3297 frames\n",
      "Signer 48 has 816 frames\n",
      "Signer 104 has 186 frames\n",
      "Signer 70 has 1136 frames\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "99bffccbd218b30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.684478Z",
     "start_time": "2025-04-01T10:38:04.638775Z"
    }
   },
   "source": "X_train, X_train_aug, y_train, X_val, X_val_aug, y_val, X_test, X_test_aug, y_test = splitter.split(X_content=lambda f: f)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 697.52it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "107083a87bfe968f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.698848Z",
     "start_time": "2025-04-01T10:38:04.696079Z"
    }
   },
   "source": [
    "# Get the total of different labels\n",
    "num_classes = num_signers\n",
    "print(num_classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fbe3d8897565f4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.749518Z",
     "start_time": "2025-04-01T10:38:04.743748Z"
    }
   },
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.fit_transform(y_val)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "931f564da905c84d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.834864Z",
     "start_time": "2025-04-01T10:38:04.791269Z"
    }
   },
   "source": [
    "BATCH_SIZE = 512\n",
    "dataset_creator = DatasetCreator()\n",
    "# TODO: add shuffle = True\n",
    "train_dataset = dataset_creator.create_custom_dataset(X_train, y_train_encoded, augmentation = X_train_aug, batch_size=BATCH_SIZE)\n",
    "val_dataset = dataset_creator.create_custom_dataset(X_val, y_val_encoded,  augmentation=X_val_aug, batch_size=BATCH_SIZE)\n",
    "test_dataset = dataset_creator.create_custom_dataset(X_test, y_test_encoded, augmentation=X_test_aug, batch_size=BATCH_SIZE)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 254200.24it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 207126.12it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 225955.77it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "44c26ae96458cfaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:04.846523Z",
     "start_time": "2025-04-01T10:38:04.844488Z"
    }
   },
   "source": [
    "xgb_params = {\n",
    "    \"objective\":\"multi:softmax\",\n",
    "    \"num_class\":num_classes,\n",
    "    \"eval_metric\":\"mlogloss\",\n",
    "    \"max_depth\":6,\n",
    "    \"learning_rate\":0.1,\n",
    "    \"n_estimators\":100,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8,\n",
    "    \"gamma\":0,\n",
    "    \"min_child_weight\":1,\n",
    "    \"reg_lambda\":1,\n",
    "    \"reg_alpha\":0,\n",
    "    \"tree_method\":\"hist\", # Change to \"gpu_hist\" for GPU acceleration\n",
    "    # \"device\":\"cuda\", # Use GPU\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ffcafd541c2b8a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T10:38:05.441904Z",
     "start_time": "2025-04-01T10:38:04.890779Z"
    }
   },
   "source": [
    "xgb_model = None\n",
    "for train_batch in tqdm(val_dataset):\n",
    "    X_batch, y_batch = train_batch.load(shuffle=True)\n",
    "    dtrain = xgb.DMatrix(X_batch, label=y_batch)\n",
    "    xgb_model = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=10, xgb_model=xgb_model)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m xgb_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_batch \u001B[38;5;129;01min\u001B[39;00m tqdm(val_dataset):\n\u001B[0;32m----> 3\u001B[0m     X_batch, y_batch \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_batch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     dtrain \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mDMatrix(X_batch, label\u001B[38;5;241m=\u001B[39my_batch)\n\u001B[1;32m      5\u001B[0m     xgb_model \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mtrain(params\u001B[38;5;241m=\u001B[39mxgb_params, dtrain\u001B[38;5;241m=\u001B[39mdtrain, num_boost_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, xgb_model\u001B[38;5;241m=\u001B[39mxgb_model)\n",
      "File \u001B[0;32m~/uni-lab/VAR/wlasl-recognition/handcrafted/app/dataset/utils/dataset_creator.py:151\u001B[0m, in \u001B[0;36mMiniBatch.load\u001B[0;34m(self, shuffle)\u001B[0m\n\u001B[1;32m    149\u001B[0m     ims \u001B[38;5;241m=\u001B[39m ims \u001B[38;5;241m+\u001B[39m augs\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f, _ \u001B[38;5;129;01min\u001B[39;00m ims:\n\u001B[0;32m--> 151\u001B[0m         features\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    152\u001B[0m         lbl\u001B[38;5;241m.\u001B[39mappend(label)\n\u001B[1;32m    153\u001B[0m features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(features)\n",
      "File \u001B[0;32m~/uni-lab/VAR/wlasl-recognition/handcrafted/app/dataset/utils/dataset_creator.py:130\u001B[0m, in \u001B[0;36mMiniBatch._extract_features\u001B[0;34m(frame)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_extract_features\u001B[39m(frame: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m--> 130\u001B[0m     hog_features, _ \u001B[38;5;241m=\u001B[39m \u001B[43mHOGExtractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_frames\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     lbp_features \u001B[38;5;241m=\u001B[39m LBPExtractor([frame])\u001B[38;5;241m.\u001B[39mget_lbp_features()\n\u001B[1;32m    132\u001B[0m     color_hist_features \u001B[38;5;241m=\u001B[39m ColorHistogram([frame], n_bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\u001B[38;5;241m.\u001B[39mprocess_frames(\n\u001B[1;32m    133\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2HSV, separate_colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     )\n",
      "File \u001B[0;32m~/uni-lab/VAR/wlasl-recognition/handcrafted/app/features/extractor/hog_extractor.py:59\u001B[0m, in \u001B[0;36mHOGExtractor.process_frames\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m processed_features \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m frame \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframes:\n\u001B[0;32m---> 59\u001B[0m     hog_features, hog_image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     processed_frames\u001B[38;5;241m.\u001B[39mappend(hog_image)\n\u001B[1;32m     61\u001B[0m     processed_features\u001B[38;5;241m.\u001B[39mappend(hog_features)\n",
      "File \u001B[0;32m~/uni-lab/VAR/wlasl-recognition/handcrafted/app/features/extractor/hog_extractor.py:77\u001B[0m, in \u001B[0;36mHOGExtractor._extract\u001B[0;34m(self, frame)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_extract\u001B[39m(\u001B[38;5;28mself\u001B[39m, frame: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     65\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Extract HOG features from a single frame.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \n\u001B[1;32m     67\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m        Tuple containing the HOG features and the processed frame.\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m     gray_frame \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvtColor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOLOR_BGR2GRAY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     hog_features, hog_image \u001B[38;5;241m=\u001B[39m hog(gray_frame, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhog_params)\n\u001B[1;32m     79\u001B[0m     hog_image \u001B[38;5;241m=\u001B[39m (hog_image \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e4741d3f0bd140a9",
   "metadata": {},
   "source": [
    "y_pred = []\n",
    "y_test_full = []\n",
    "for test_batch in tqdm(test_dataset):\n",
    "    X_batch, y_batch = test_batch.load(shuffle=True)\n",
    "    y_test_full.extend(y_batch)\n",
    "    dtest = xgb.DMatrix(X_batch)\n",
    "    y_pred_batch = xgb_model.predict(dtest)\n",
    "    y_pred.extend(y_pred_batch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "374f709d5e515120",
   "metadata": {},
   "source": [
    "stats = ModelStatistics(save_name=f\"svc_signer_test_{len(y_test_full)}\", save_dir=\"signer/plots\")\n",
    "stats.print_accuracy(y_test_full, y_pred)\n",
    "stats.plot_confusion_matrix(y_test_full, y_pred, save=True, plot=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
